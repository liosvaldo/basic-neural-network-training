{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Atividade_1_Modulo_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1WHIrghC3gHDtrmsbUEateHs4G6gJOa1A",
      "authorship_tag": "ABX9TyO9S9x4nWjHywZRUeiKUMbH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Atividade Rede neural de treinamento com dados de paisagem\n",
        "\n",
        "1. Quantas camadas foram utilizadas? Houve alteração de desempenho aumentando ou diminuindo a quantidade de camadas?\n",
        "R: Utilizamos 1 camada de entrada, 2 ocultas e a de saida. Tivemos um aumento no aprendizado até este tamanho. Logo em seguida tivemos um decaimento. \n",
        "\n",
        "2. Quantos neurônios em cada camada? Houve alteração de desempenho aumentando ou diminuindo a quantidade de camadas?\n",
        "R: Utilizamos uma camada de entrada com 1028 atributo e duas camadas ocultas com 512 e 218 atributos, todas com uma ativação modelo relu\n",
        "\n",
        "\n",
        "3. Foi necessário utilizar técnicas de regularização?\n",
        "Sim: Idealmente mantivemos apenas a Early Stopping, entretanto também foi testado a dropout. (Não sei se o checkpoint pode ser considerado uma técnica);\n",
        "\n",
        "4. Qual a avaliação do modelo? Houve overfiting?\n",
        "R: Com base nas técnicas utilizadas, observou-se um overfiting que pode ser desconsideravel (Menor que 10 pontos)\n",
        "\n",
        "5. Realize a leitura da base de teste e aplique o mesmo pré-processamento do treinamento (base seq_test). Houve alteração no desempenho na base de teste?\n",
        "R: sim, tivemos uma queda de 5 pontos\n",
        "\n",
        "6. Altere a dimensão dos dados de entrada (setados inicialmente com 150x150). Houve diferença no desempenho?\n",
        "R: Não foi possível utilizar os dados de entrada desejados (150x150) tivemos um ouverflow da maquina. Utilizou-se (120x120). Entretanto, matematicamente falando, teremos uma redução de pixels na nossa imagem. Semelhantemente ao olho humano, uma maior dificuldade de identificar traços. Logo é previsivel que tenhamos uma queda no desempenho da rede.\n",
        "\n",
        "7. [Desafio bônus]: Como está a distribuição das classes? Oversampling (data augmentation) melhoraria o desempenho desta base?\n",
        "R: Não foi testado nenhum metodo deste tipo. Entretanto, vale lembrar que algumas classes tendem a ser bem parecidas. Logo seria interessante o data augmentation para atenuar essas semelhanças. \n",
        "\n",
        "Podemos observar esse tipo de dificuldade da rede em generalizar com base na matriz de confusão\n",
        "\n"
      ],
      "metadata": {
        "id": "DHt4rJJSzRBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ezw0tK61zQxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando dados"
      ],
      "metadata": {
        "id": "XS9Yv07oT_du"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcygBvYATssv"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plot\n",
        "from random import randint\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando arquivos"
      ],
      "metadata": {
        "id": "w3texQZNUDyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "instalando o gdown"
      ],
      "metadata": {
        "id": "JF0XRVlTUR1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqqq gdown\n",
        "!gdown 1XNSk1lEudBy8vYUNMx7De455UB5AwG-Y"
      ],
      "metadata": {
        "id": "7LY30SrFT-Nd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff19b983-bcf7-4655-c36e-46f7ad543955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XNSk1lEudBy8vYUNMx7De455UB5AwG-Y\n",
            "To: /content/dataset.zip\n",
            "100% 374M/374M [00:02<00:00, 165MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "b23DfAk_UqcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.unpack_archive('dataset.zip', 'dataset')"
      ],
      "metadata": {
        "id": "zPxtvin-UsUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo das paisagens"
      ],
      "metadata": {
        "id": "3nilGnXEaseK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "for files in glob.glob(\"/content/dataset/dataset/seg_train/**/*.jpg\", recursive = True):\n",
        "  image = cv2.imread(files)\n",
        "  image = cv2.resize(image, (100,100))\n",
        "  X.append(image)\n",
        "  y.append(files.split('/')[-2])"
      ],
      "metadata": {
        "id": "pNM5C5JMV209"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSIMxLtWXV-t",
        "outputId": "f4a8b7c2-034d-4595-8306-1c849f23a79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14034, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Divisão de treino e teste da base"
      ],
      "metadata": {
        "id": "m_5CwWVyYtf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "WSc3W4rAYxG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Separando as classes de y"
      ],
      "metadata": {
        "id": "T9-sUWLqZXZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot = OneHotEncoder()\n",
        "y_train = onehot.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
        "y_val = onehot.fit_transform(y_val.reshape(-1,1)).toarray()"
      ],
      "metadata": {
        "id": "ETD583j8ZVcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = np.max(X_train) # valor maximo de rgb\n",
        "\n",
        "X_train = X_train/m\n",
        "X_val = X_val/m"
      ],
      "metadata": {
        "id": "nn3LqUhjZ2_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "doC6Zj7Oa05i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.prod(X_train.shape[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEcr8TUBbPNl",
        "outputId": "750244c9-c594-4b16-8462-e372fdc86d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4-_o2DbcU2y",
        "outputId": "7ecaa27a-8fc0-4308-a111-c4d5740ec7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9402, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Arquitetura"
      ],
      "metadata": {
        "id": "GVXFscEiem8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rede_simples = Sequential()\n",
        "rede_simples.add(Flatten())\n",
        "rede_simples.add(Dense(1028, input_dim=np.prod(X_train.shape[1:])))\n",
        "# rede_simples.add(Dropout(0.7))\n",
        "rede_simples.add(Activation('relu'))\n",
        "rede_simples.add(Dense(512))\n",
        "# rede_simples.add(Dropout(0.5))\n",
        "rede_simples.add(Activation('relu'))\n",
        "rede_simples.add(Dense(218))\n",
        "# rede_simples.add(Dropout(0.7))\n",
        "rede_simples.add(Activation('relu'))\n",
        "rede_simples.add(Dense(6))\n",
        "rede_simples.add(Activation('softmax'))\n"
      ],
      "metadata": {
        "id": "Z5CE79ndceX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede_simples.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', \n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QV62zmgeehvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treinamento"
      ],
      "metadata": {
        "id": "jj4yGXwoemFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n",
        "                    patience = 5,\n",
        "                    verbose = 1, \n",
        "                    mode = 'auto')\n",
        "\n",
        "check = ModelCheckpoint(\n",
        "    filepath='/content/Pickles/pickle1.sav',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        " \n",
        "historico = rede_simples.fit(X_train, \n",
        "                             y_train, \n",
        "                             epochs = 50,\n",
        "                             batch_size=64,\n",
        "                             verbose = 1,\n",
        "                             validation_data = (X_val, y_val),\n",
        "                             callbacks=[es, check]\n",
        "                             )"
      ],
      "metadata": {
        "id": "gjuL386velf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Recuperar o melhor modelo"
      ],
      "metadata": {
        "id": "FRnIrWlVV7cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rede_simples.load_weights('/content/Pickles/pickle2.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dro722uWV9_X",
        "outputId": "1f38deb3-a506-4ddb-fe76-0774e4e10f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<tensorflow.python.keras.layers.core.Dense object at 0x7f0c400adc50> and <tensorflow.python.keras.layers.core.Activation object at 0x7f0c400ada10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<tensorflow.python.keras.layers.core.Dense object at 0x7f0c400adf90> and <tensorflow.python.keras.layers.core.Activation object at 0x7f0c400ade10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<tensorflow.python.keras.layers.core.Dense object at 0x7f0c400a0990> and <tensorflow.python.keras.layers.core.Dropout object at 0x7f0bcee4e4d0>).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0c4bc4ee10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pred_simples = rede_simples.predict(X_val)\n",
        "\n",
        "accuracy_score(y_val.argmax(1), pred_simples.argmax(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N66k9P4qWfHT",
        "outputId": "91995024-9e88-44f6-8f1c-742a78df9567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5990932642487047"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "for files in glob.glob(\"/content/dataset/dataset/seg_test/**/*.jpg\", recursive = True):\n",
        "  image = cv2.imread(files)\n",
        "  image = cv2.resize(image, (100,100))\n",
        "  X.append(image)\n",
        "  y.append(files.split('/')[-2])"
      ],
      "metadata": {
        "id": "oy4iAx1PWezP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX5QvvSaWeJ4",
        "outputId": "164d3d5b-c345-434b-a2fc-fbb241ed008c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot = OneHotEncoder()\n",
        "y_test = onehot.fit_transform(y.reshape(-1, 1)).toarray()\n",
        "# y_val = onehot.fit_transform(y_val.reshape(-1,1)).toarray()"
      ],
      "metadata": {
        "id": "3Lqtov1BWd0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_simples = rede_simples.predict(X)\n",
        "\n",
        "accuracy_score(y_test.argmax(1), pred_simples.argmax(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sCfVLYGXMjs",
        "outputId": "0af38225-6d9a-45be-a086-db7ce6f40f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5563333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = historico.history['loss']\n",
        "val_loss = historico.history['val_loss']\n",
        "epochs = range(len(loss))\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zNdBw7S5fvRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede_simples.save('/content/drive/MyDrive/Santander/Modulo 5/Atividade 1/pickle_paisagem.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFAd1nd1JKUC",
        "outputId": "0c2050ee-252e-45e5-c8f9-8b21851ddbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Santander/Modulo 5/Atividade 1/pickle_paisagem.sav/assets\n"
          ]
        }
      ]
    }
  ]
}